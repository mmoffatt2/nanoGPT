# muon_vs_adamw_finewebedu.yaml
---
parameter_groups:
  - optimizer: ["adamw"]
    learning_rate: ["0.05"]
    beta1: [0.9]
    beta2: [0.99]
    adamw_weight_decay: [0.1]
    adamw_eps: ["1e-8"]
  - optimizer: ["muon"]
    learning_rate: ["0.05"]
    muon_momentum: [0.95]

# GPT-2 architecture base hyperparameters
n_layer: [6]
n_head: [6]
n_embd: [384]
block_size: [256]
batch_size: [64]
max_iters: [10000]
eval_interval: [10000]
eta_variant: ["iteration"]
dataset: ["minipile"]
device: ["cuda"]
dtype: ["float16"]
use_abs_pos_embeddings: [false]
use_rotary_embeddings: [true]
use_qk_norm: [true]
use_qk_norm_scale: [true]
use_peri_ln: [true]
softmax_variant_attn: ["softmax"]
compile: [true]
never_save_checkpoint: [true]
tensorboard_run_name: ["muon_vs_adamw"]
